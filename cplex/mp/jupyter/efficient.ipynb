{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing efficient DOcplex code\n",
    "\n",
    "In this notebook, we show how to improve efficiency of DOcplex models using five simple rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple timing tool\n",
    "\n",
    "To measure performance we need a simple timing tool. For this purpose, we chose to implement a Python context manager object (see https://docs.python.org/3/reference/datamodel.html#context-managers) for details.\n",
    "\n",
    "This object stores the start time when entering a block and reports time spent when exiting the block. Python's `with` statement avoids cluttering code with intrusive prints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "class ContextTimer(object):\n",
    "    def __init__(self, msg):\n",
    "        self.msg = msg\n",
    "        self.start = 0\n",
    "        \n",
    "    def __enter__(self):\n",
    "        self.start = time.time()\n",
    "        return self  # return value is value of with ()\n",
    "        \n",
    "    def __exit__(self, *args):\n",
    "        elapsed = time.time() - self.start\n",
    "        self.msecs = math.ceil(1000* elapsed)\n",
    "        print('<-- {0},  time: {1:.0f} ms'.format(self.msg, self.msecs))   \n",
    "        \n",
    "# try our timer on computing fibonacci numbers\n",
    "def fib(n):\n",
    "    return 1 if n <= 2 else  fib(n-1) + fib(n-2)\n",
    "\n",
    "# timing fibonacci(30)\n",
    "with ContextTimer(\"fibonacci 30\"):\n",
    "    n = 30\n",
    "    f = fib(n)\n",
    "    print(\"fibonacci({0}) = {1}\".format(n, f))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The benchmark model\n",
    "\n",
    "To compare various implementations, we need a simple, scalable benchmark model. The model has no real business meaning, but is simple to grasp\n",
    "and can be scaled by changing one `size` parameter.\n",
    "Note that we'll be comparing only the _build_ time of the model, not the _solve_ time.\n",
    "\n",
    "Note that the model has _n_ constraints, all with expressions of size _N_, so we expect the underlying matrix _size_ to grow as $O(N^2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "Let $N$ be an integer (the size of the problem).\n",
    "\n",
    "$$\n",
    "minimize \\sum_{k=0}^{k=N-1} (k+1) * y_{k}\\\\\n",
    "s.t.\\\\\n",
    "\\forall\\ \\ m\\ in \\{0..N-1\\}\\ \\ \\sum_{l=0}^{l=N-1} (y_{l} * (l+ (l+m) \\%3) \\ge l\\\\\n",
    "y_{k} = 0, 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A beginners's implementation of the model\n",
    "\n",
    "In this section we show a Python/Docplex beginner's implementation of this model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from docplex.mp.model import Model\n",
    "\n",
    "def build_bench_model1(size=10):\n",
    "    m = Model(name=\"bench1\")\n",
    "    rsize = range(size)\n",
    "    # create variables as a dictionary indexed by the range\n",
    "    ys = m.binary_var_dict(rsize, name=\"y\")\n",
    "    # create constraints\n",
    "    k = {(i,j) : (i + (i+j) %3) for i in rsize for j in rsize}\n",
    "    for i in rsize:\n",
    "        m.add(m.sum(ys[i] * k[i,j] for j in rsize) >= i, \"ct_%d\" %i)\n",
    "    # for minimize, create a list of coefficients\n",
    "    rsize1 = [i+1 for i in rsize]\n",
    "    m.minimize(m.sum(ys[k] * rsize[k] for k in rsize))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run our context timer with N=1000; we expect a model with 1000 variables and 1000 constraints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with ContextTimer(\"bench1_size_1000\"):\n",
    "    m11k = build_bench_model1(1000)\n",
    "m11k.print_information()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the model has 1000 variables and 1000 constraints and the build time is significant.\n",
    "For N=3000, we can expect an increase in buid time by a factor of 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N=3000\n",
    "with ContextTimer(\"bench1 size={0}\".format(N)):\n",
    "    build_bench_model1(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seven tips to improve DOcplex code efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use scalar product\n",
    "\n",
    "When building large expressions,  scalar product (`Model.scal_prod()`) is \n",
    "an efficient way to combine a sequence of variables (or expressions)\n",
    "and a sequence of coefficients.\n",
    "Try using `scalar_prod` instead of using `for` loops in expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_bench_model2(size=10):\n",
    "    m = Model(name=\"bench2\")\n",
    "    rsize = range(size)\n",
    "    # create variables as a dictionary indexed by the range\n",
    "    ys = m.binary_var_dict(rsize, name=\"y\")\n",
    "    # create constraints\n",
    "    k = {(i,j) : (i + (i+j) %3) for i in rsize for j in rsize}\n",
    "    for i in rsize:\n",
    "        m.add(m.scal_prod([ys[i1] for i1 in rsize], [k[i,j] for j in rsize]) >= i, \"ct_%d\" % i)\n",
    "    # for minimize, create a list of coefficients\n",
    "    rsize1 = [i+1 for i in rsize]\n",
    "    m.minimize(m.scal_prod([ys[k] for k in rsize], rsize1))\n",
    "    return m\n",
    "\n",
    "with ContextTimer(\"bench3 size={0}\".format(N)):\n",
    "    build_bench_model2(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use variable lists instead of dicts, if possible\n",
    "\n",
    "In the previous examples, we had to create an auxiliary sequence from the variable dictionary to pass to `scal_prod`. Actually, a variable _list_ would be much simpler to use than the dictionary, so we replace the `var_dict` by a `var_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_bench_model21(size=10):\n",
    "    m = Model(name=\"bench2.1\")\n",
    "    rsize = range(size)\n",
    "    # create variables as a dictionary indexed by the range\n",
    "    ys = m.binary_var_list(rsize, name=\"y\")\n",
    "    # create constraints\n",
    "    k = {(i,j) : (i + (i+j) %3) for i in rsize for j in rsize}\n",
    "    for i in rsize:\n",
    "        m.add(m.scal_prod(ys, [k[i,j] for j in rsize]) >= i, \"ct_%d\" % i)\n",
    "    # for minimize, create a list of coefficients\n",
    "    rsize1 = [i+1 for i in rsize]\n",
    "    m.minimize(m.scal_prod(ys, rsize1))\n",
    "    return m\n",
    "\n",
    "with ContextTimer(\"bench2.1 size={0}\".format(N)):\n",
    "    build_bench_model21(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use batches of constraints\n",
    "\n",
    "Adding constraints to the model by batches using `Model.add_constraints()`\n",
    "is usually more efficient.\n",
    "Try grouping consttraints in lists or comprehensions (both work).\n",
    "\n",
    "If the constraints are named, pass a second argument with the collection of constraint names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_bench_model3(size=10):\n",
    "    m = Model(name=\"bench3\")\n",
    "    rsize = range(size)\n",
    "    # create variables as a dictionary indexed by the range\n",
    "    ys = m.binary_var_list(rsize, name=\"y\")\n",
    "    # create constraints\n",
    "    k = {(i,j) : (i + (i+j) %3) for i in rsize for j in rsize}\n",
    "    m.add_constraints((m.scal_prod(ys, [k[i,j] for j in rsize]) >= i for i in rsize),\n",
    "                     [\"ct_%d\" % i for i in rsize])\n",
    "    # for minimize, create a list of coefficients\n",
    "    rsize1 = [i+1 for i in rsize]\n",
    "    m.minimize(m.scal_prod(ys, rsize1))\n",
    "    return m\n",
    "\n",
    "with ContextTimer(\"bench3 size={0}\".format(N)):\n",
    "    build_bench_model3(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoid creating unnecessary containers\n",
    "\n",
    "The previous version allocated one dictionary `k` for coefficients and an auxiliary list for the objective. We can simplify the code bys using comprehensions instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_bench_model4(size=10):\n",
    "    m = Model(name=\"bench4\")\n",
    "    rsize = range(size)\n",
    "    # create variables as a dictionary indexed by the range\n",
    "    ys = m.binary_var_list(rsize, name=\"y\")\n",
    "    # create constraints\n",
    "    m.add_constraints((m.scal_prod(ys, [(i+ (i+j)%3) for j in rsize]) >= i for i in rsize),\n",
    "                     (\"ct_%d\" % i for i in rsize))\n",
    "    # for minimize, create a list of coefficients\n",
    "    m.minimize(m.scal_prod(ys, (i+1 for i in rsize)))\n",
    "    return m\n",
    "\n",
    "with ContextTimer(\"bench4 size={0}\".format(N)):\n",
    "    build_bench_model4(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take control of name generation\n",
    "\n",
    "Naming variables and/or constraints is useful to generate readable LP files. However, generating lare numbers of strings may have a significant cost in Python, sepcially for large models. \n",
    "\n",
    "DOcplex provides a keyword `ignore_names` at model creation time, which may disable all names (variables and constraint names alike) that are set in the model. \n",
    "\n",
    "By default, this flag is  `False`, and names are enabled. By setting this flag to `True`, all names mentioned in the model are discarded (in particular, names are not used in LP generation).\n",
    "\n",
    "In the next version we simply add the `ignore_names=True` keyword argument to the model constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_bench_model5(size=10):\n",
    "    m = Model(name=\"bench5\", ignore_names=True)\n",
    "    rsize = range(size)\n",
    "    # create variables as a dictionary indexed by the range\n",
    "    ys = m.binary_var_list(rsize, name=\"y\")\n",
    "    # create constraints\n",
    "    m.add_constraints((m.scal_prod(ys, [(i+ (i+j)%3) for j in rsize]) >= i for i in rsize),\n",
    "                     (\"ct_%d\" % i for i in rsize))\n",
    "    # for minimize, create a list of coefficients\n",
    "    m.minimize(m.scal_prod(ys, (i+1 for i in rsize)))\n",
    "    return m\n",
    "\n",
    "with ContextTimer(\"bench6 size={0}\".format(N)):\n",
    "    build_bench_model5(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take control of argument checking\n",
    "\n",
    "DOcplex does a minimal checking on arguments. As this can be useful when writing the model to avoid errors, this checking has a runtime cost. When running a deployed model that has been thoroughly tested and tuned, you can remove all checks by adding the `checker=\"off\"` keyword argument to the model constructor.\n",
    "\n",
    "Again, the next version is identical to the previous one , except that type-checking has been disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_bench_model6(size=10):\n",
    "    m = Model(name=\"bench6\", ignore_names=True, checker=\"off\")\n",
    "    rsize = range(size)\n",
    "    # create variables as a dictionary indexed by the range\n",
    "    ys = m.binary_var_list(rsize, name=\"y\")\n",
    "    # create constraints\n",
    "    m.add_constraints((m.scal_prod(ys, [(i+ (i+j)%3) for j in rsize]) >= i for i in rsize),\n",
    "                     (\"ct_%d\" % i for i in rsize))\n",
    "    # for minimize, create a list of coefficients\n",
    "    m.minimize(m.scal_prod(ys, (i+1 for i in rsize)))\n",
    "    return m\n",
    "\n",
    "with ContextTimer(\"bench6 size={0}\".format(N)):\n",
    "    build_bench_model6(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the \"advanced model\" class\n",
    "\n",
    "DOcplex contains and `AdvModel` class, which is a subclass of `Model`.\n",
    "This class contains highly efficient methods for special cases, for examples, scalar prodicts with all different variables. \n",
    "By default, `AdvModel` methods do not perform any checking on their arguments. For example, the `cal_prod_vars_all_different` method does not check that the variables are indeed all different. If this is not true, then errors or incorrect results may occur.\n",
    "\n",
    "Still, you can enable type-checking on AdvModel by specifying `checker=\"on\"` at construction time, and remove it later.\n",
    "\n",
    "The benchmark model is a good fit for the `scal_prod_vars_all_different` method as all our scalar products involve the `ys` variables.\n",
    "\n",
    "AdvModel provides other specialized fast method, among them:\n",
    "\n",
    " - `sum_vars_all_different` to compute the sum of a sequence of all different variables.\n",
    " - `quad_matrix_sum` to compute a quadratic expression from a matrix $Q$ and a vector of variables $X$ as $X^{t}QX$\n",
    " - `vector_compare` to compute a sequence of linear constraint from two sequences of expressions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from docplex.mp.advmodel import AdvModel\n",
    "\n",
    "def build_bench_model7(size=10):\n",
    "    m = AdvModel(name=\"bench7\", ignore_names=True, checker='off')\n",
    "    rsize = range(size)\n",
    "    # create variables as a dictionary indexed by the range\n",
    "    ys = m.binary_var_list(rsize, name=\"y\")\n",
    "    # create constraints\n",
    "    m.add_constraints((m.scal_prod_vars_all_different(ys, [(i+ (i+j)%3) for j in rsize]) >= i for i in rsize),\n",
    "                 (\"ct_%d\" % i for i in rsize))\n",
    "    \n",
    "    # for minimize, use comprehension\n",
    "    m.minimize(m.scal_prod_vars_all_different(ys, (i+1 for i in rsize)))\n",
    "    return m\n",
    "\n",
    "with ContextTimer(\"bench7 size={0}\".format(N)):\n",
    "    build_bench_model7(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "From version 1 to version 7 , model build time has decreased from 35s to 4s (on our platform). Result smay well differ on other platforms, but still, this demonstrates that the way the model is built can greatly influence the performance.\n",
    "\n",
    "Here is a list of tricks to try to improve model building time:\n",
    "\n",
    " - Use Model.scal_prod wherever possible\n",
    " - Add constraints in batches, not one by one\n",
    " - Leverage Python comprehensions to avoid unnecessary data structures\n",
    " - Try ignoring name generation (for large models)\n",
    " - Try disabling all argument checking\n",
    " - Eventually, look at specialized methods in the `AdvModel` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the trend\n",
    "\n",
    "In this section we compute the times to build different model versions on various sizes, and\n",
    "plot the result on a graph.\n",
    "This code requires the `matplotlib` library to run.\n",
    "\n",
    "**Note**: the next cell might take a significant time to run, as it\n",
    "runs a lot of (size, model_build_function) combinations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# various sizes to sample performance\n",
    "sizes = [100, 300, 600, 1000, 3000, 5000]\n",
    "\n",
    "# a lits of tuples (fn, label) to build model and an explanatory label\n",
    "builders = [(build_bench_model1, \"initial\"), \n",
    "            (build_bench_model2, \"scal_prod\"),\n",
    "            (build_bench_model4, \"batch_cts\"),\n",
    "            (build_bench_model5, \"ignore_names\"),\n",
    "            (build_bench_model6, \"checker_off\"),\n",
    "            (build_bench_model7, \"advmodel\")]\n",
    "print(\"* start computing performance data\")\n",
    "res = {}\n",
    "print(\"* start computing results...\")\n",
    "nb_runs = len(sizes) * len(builders)\n",
    "r = 0\n",
    "for s in sizes:\n",
    "    for b, (bf, _) in enumerate(builders):\n",
    "        r +=1 \n",
    "        with ContextTimer(\"[{2}/{3}] use {0} with size={1}\"\n",
    "                          .format(bf.__name__, s, r, nb_runs)) as tt:\n",
    "            m = bf(s)\n",
    "            m.end()\n",
    "        elapsed = tt.msecs\n",
    "        res[b, s] = tt.msecs\n",
    "print(\"* end computing results\")\n",
    "# now we have a dict of (#builder, size) -> time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "except ImportError:\n",
    "    print(\"try install matplotlib: pip install matplotlib\")\n",
    "    raise\n",
    "\n",
    "\n",
    "labels = [ bl for (_, bl) in builders]\n",
    "plt.figure(figsize=(16,7))\n",
    "for b in range(len(builders)):\n",
    "    bts = [res[b,s]/1000 for s in sizes]\n",
    "    plt.plot(sizes, bts, label=labels[b])\n",
    "    plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average improvement\n",
    "\n",
    "In the next cell, we compute the geometric mean of improvment between the first and last versions. Of course, results may differ depending on platform (and the model, too) but the idea is, applying the above rules may yield a significant improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute geomerical mean for all sizes\n",
    "nb_builders = len(builders)\n",
    "ratios = {}\n",
    "for s in sizes:\n",
    "    initial = res[0, s]\n",
    "    final = res[nb_builders-1, s]\n",
    "    r = (initial/final)\n",
    "    ratios[s] = r\n",
    "import math\n",
    "rgm = math.exp(sum(math.log(r) for r in ratios.values()) / float(nb_builders))\n",
    "print(\"* geometric mean of time improvement is {0:.1f}\".format(rgm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
